# Voice AI Assistant (Groq-Powered)

A Next.js application that provides real-time voice interaction using Groq's fast AI APIs for speech-to-text and chat completion, with local text-to-speech synthesis.

## Features

- ðŸŽ¤ **Real Speech-to-Text**: Uses Groq's Whisper API for fast, accurate transcription
- ðŸ¤– **Groq Chat Integration**: Powered by Llama 3.1 70B for intelligent responses
- ðŸ”Š **Local Text-to-Speech**: Synthesizes AI responses locally using cached TTS
- ðŸ“± **PWA Support**: Installable as a Progressive Web App
- âš¡ **Performance Monitoring**: Real-time latency tracking with < 1.2s target
- ðŸ”„ **Offline UI**: Works offline for cached content, requires internet for AI features

## Architecture

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Main Thread   â”‚    â”‚   Groq APIs      â”‚    â”‚  Service Worker â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ UI Components â”‚    â”‚ â€¢ Whisper STT    â”‚    â”‚ â€¢ Asset Caching â”‚
â”‚ â€¢ Audio Recordingâ”‚â—„â”€â”€â–ºâ”‚ â€¢ Llama Chat     â”‚    â”‚ â€¢ Offline Mode  â”‚
â”‚ â€¢ Local TTS     â”‚    â”‚ â€¢ Fast Inference â”‚    â”‚ â€¢ Cache Strategyâ”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

## Setup Instructions

### Prerequisites

- Node.js 18+ 
- npm or pnpm
- Groq API key (free tier available)

### Environment Variables

Create a `.env.local` file in the root directory:

\`\`\`env
GROQ_API_KEY=your_groq_api_key_here
\`\`\`

Get your free Groq API key at: https://console.groq.com/keys

### Installation

1. Clone the repository:
\`\`\`bash
git clone <repository-url>
cd offline-voice-ai
\`\`\`

2. Install dependencies:
\`\`\`bash
npm install
# or
pnpm install
\`\`\`

3. Run the development server:
\`\`\`bash
npm run dev
# or
pnpm dev
\`\`\`

4. Open [http://localhost:3000](http://localhost:3000) in your browser

### Production Build

\`\`\`bash
npm run build
npm start
\`\`\`

## Usage

1. **Setup**: Add your Groq API key to `.env.local`
2. **Recording**: Click the microphone button to start recording
3. **Processing**: Speech is transcribed using Groq's Whisper API
4. **Chat**: Transcription is sent to Groq's Llama model for response
5. **Playback**: AI response is synthesized locally and played back

## API Endpoints

### `/api/transcribe`
- **Method**: POST
- **Body**: FormData with audio file
- **Response**: Transcribed text using Groq Whisper

### `/api/chat`
- **Method**: POST  
- **Body**: JSON with text
- **Response**: AI response using Groq Llama 3.1

## Performance Targets

- **STT Latency**: < 500ms (Groq Whisper is very fast)
- **Chat Latency**: < 300ms (Groq inference is optimized for speed)
- **TTS Latency**: < 400ms (local synthesis)
- **Total Response Time**: < 1.2s

## Groq API Benefits

- **Fast Inference**: Groq's hardware is optimized for speed
- **Free Tier**: Generous free usage limits
- **High Quality**: Whisper-large-v3 and Llama 3.1 70B models
- **Reliable**: Enterprise-grade API infrastructure

## File Structure

\`\`\`
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ transcribe/route.ts   # Groq Whisper API
â”‚   â”‚   â””â”€â”€ chat/route.ts         # Groq Chat API
â”‚   â”œâ”€â”€ layout.tsx                # Root layout with PWA meta
â”‚   â”œâ”€â”€ page.tsx                  # Main voice interface
â”‚   â””â”€â”€ globals.css               # Global styles
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ sw.js                     # Service Worker
â”‚   â”œâ”€â”€ manifest.json             # PWA manifest
â”‚   â””â”€â”€ workers/
â”‚       â””â”€â”€ tts-worker.js         # TTS Web Worker
â””â”€â”€ components/ui/                # shadcn/ui components
\`\`\`

## Browser Compatibility

- Chrome 88+
- Firefox 84+
- Safari 14+
- Edge 88+

Requires:
- MediaRecorder API
- Web Audio API
- Fetch API with FormData

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## License

MIT License - see LICENSE file for details
